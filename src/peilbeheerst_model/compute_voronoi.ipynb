{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c447874-07f5-4c13-9d5f-f2a3063ae446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import centerline.geometry\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely\n",
    "import shapely.geometry\n",
    "import tqdm.auto as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811cd9a-bd64-4dc6-92f3-b302f7d4ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(\"../../../../Data_postprocessed/Waterschappen/Wetterskip/Wetterskip.gpkg\", layer=\"peilgebied\")\n",
    "df[\"geometry\"] = df.buffer(0)\n",
    "df = df[~df.is_empty].copy()\n",
    "df[\"geometry\"] = df.geometry.apply(shapely.force_2d)\n",
    "df = df[df.peilgebied_cat == 1].copy()\n",
    "\n",
    "df_crossings = gpd.read_file(\"../../../../Data_crossings/Wetterskip/wetterskip_crossings_v05.gpkg\", layer=\"crossings_hydroobject_filtered\")\n",
    "df_crossings = df_crossings[df_crossings.agg_links_in_use].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b86228-791d-475d-ac64-ce27e5e50f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge polygons with a small buffer. Ook nodig om verbindingen te krijgen in sommige smalle watergangen.\n",
    "df_merged = df.buffer(1.0).unary_union\n",
    "df_merged = gpd.GeoDataFrame(geometry=list(df_merged.geoms), crs=df.crs)\n",
    "\n",
    "# add merged id to original polygons\n",
    "merged_poly_ids = []\n",
    "for row in tqdm.tqdm(df.itertuples(), total=len(df)):\n",
    "    idxs = df_merged.sindex.query(row.geometry, predicate=\"intersects\")\n",
    "    if len(idxs) == 0:\n",
    "        raise ValueError(\"no matches\")\n",
    "    elif len(idxs) > 1:\n",
    "        overlaps = []\n",
    "        for idx in idxs:\n",
    "            overlap = df_merged.iat[idx].intersection(row.geometry).area / row.geometry.area\n",
    "            overlaps.append(overlap)\n",
    "        idx = idxs.index(max(overlaps))\n",
    "    else:\n",
    "        idx = idxs[0]\n",
    "    merged_poly_ids.append(idx)\n",
    "df[\"merged_poly_id\"] = merged_poly_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea23b73-0db8-4bac-ba30-b36faa3e224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_center = []\n",
    "for idx, row in tqdm.tqdm(df_merged.iterrows(), total=len(df_merged)):\n",
    "    geom = row.geometry\n",
    "    interp_dist = 10\n",
    "    if geom.area < 1000:\n",
    "        interp_dist = 1\n",
    "    if geom.area < 100:\n",
    "        interp_dist = 0.1\n",
    "    if geom.area < 10:\n",
    "        interp_dist = 0.01\n",
    "    if geom.area < 1:\n",
    "        interp_dist = 0.001\n",
    "    centerpoly = centerline.geometry.Centerline(geom, interpolation_distance=interp_dist)\n",
    "    centerpoly = centerpoly.geometry\n",
    "    centerpoly = centerpoly.simplify(1, preserve_topology=True)\n",
    "    df_center.append(centerpoly)\n",
    "df_center = gpd.GeoDataFrame(geometry=list(df_center), crs=df.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f7bf3-4c68-46b9-a7a8-caf8e1868b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_center_single = df_center.explode(index_parts=False)\n",
    "df_center_single = df_center_single.set_index(np.arange(len(df_center_single)), append=True)\n",
    "df_center_single.index.set_names([\"poly_id\", \"edge_id\"], inplace=True)\n",
    "\n",
    "df_center_single_boundary = df_center_single.copy()\n",
    "df_center_single_boundary[\"geometry\"] = df_center_single.boundary\n",
    "\n",
    "# # Check of alles mooi verbonden is\n",
    "# for i, row in tqdm.tqdm(enumerate(df_center_single_boundary.itertuples()), total=len(df_center_single_boundary), desc=\"check connections\"):\n",
    "#     idx = row.Index\n",
    "#     geom = row.geometry\n",
    "\n",
    "#     idxs, dists = df_center_single_boundary.sindex.nearest(geom, return_distance=True, return_all=True)\n",
    "#     idxs = idxs[1, :]\n",
    "#     dists = dists[idxs != i]\n",
    "#     idxs = idxs[idxs != i]\n",
    "#     if dists.min() > 0:\n",
    "#         print(f\"no closed connection for {idx}, {dist.min()=}\")\n",
    "#     elif len(idxs) == 0:\n",
    "#         print(f\"No connection for {idx}: {df_center_single_boundary.iloc[idxs].index}\")\n",
    "\n",
    "df_center_single_boundary_points = df_center_single_boundary.explode(index_parts=True)\n",
    "df_center_single_boundary_points[\"node_id\"] = None\n",
    "df_center_single_boundary_points[\"connectivity\"] = None\n",
    "\n",
    "node_id = 0\n",
    "idxs, node_ids, connectivity = [], [], []\n",
    "for poly_id, poly_group in tqdm.tqdm(df_center_single_boundary_points.groupby(\"poly_id\", sort=False), desc=\"assign node ids\"):\n",
    "    for geom, group in tqdm.tqdm(poly_group.groupby(\"geometry\", sort=False), desc=f\"{poly_id=}\", leave=False):\n",
    "        idxs.append(group.index)\n",
    "        node_ids.append(len(group) * [node_id])\n",
    "        connectivity.append(len(group) * [len(group)])\n",
    "        node_id += 1\n",
    "\n",
    "df_center_single_boundary_points.loc[np.hstack(idxs), \"node_id\"] = np.hstack(node_ids)\n",
    "df_center_single_boundary_points.loc[np.hstack(idxs), \"connectivity\"] = np.hstack(connectivity)\n",
    "idxs, node_ids, connectivity = None, None, None\n",
    "\n",
    "assert not pd.isna(df_center_single_boundary_points.node_id).any()\n",
    "assert not pd.isna(df_center_single_boundary_points.connectivity).any()\n",
    "\n",
    "df_center_single_boundary_points = df_center_single_boundary_points.droplevel(-1).set_index(\"node_id\", append=True)\n",
    "df_center_single_boundary_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794fa1a-89b2-4bdf-899d-d19d5077fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alleen edges proberen te mergen waarvan beide uiteindes (nodes) connectivity 2 hebben\n",
    "pot_reduce = []\n",
    "for edge_id, group in tqdm.tqdm(df_center_single_boundary_points.groupby(\"edge_id\", sort=False), desc=\"Find connectivity=2\"):\n",
    "    if (group.connectivity == 2).all():\n",
    "        pot_reduce.append(edge_id)\n",
    "pot_reduce = df_center_single_boundary.loc[pd.IndexSlice[:, pot_reduce], :].copy()\n",
    "\n",
    "# Identify merge groups\n",
    "edges_visited = {}\n",
    "merge_group = 0\n",
    "pot_reduce[\"merge_group\"] = None\n",
    "for poly_id, polygroup in tqdm.tqdm(pot_reduce.groupby(\"poly_id\", sort=False), desc=\"group edges per polygon\"):\n",
    "    for edge_id, group in tqdm.tqdm(polygroup.groupby(\"edge_id\", sort=False), leave=False, desc=f\"{poly_id=}\"):\n",
    "        if edge_id in edges_visited:\n",
    "            continue\n",
    "    \n",
    "        ivec = np.where(polygroup.index.isin(group.index))[0]\n",
    "        prev_len = 0\n",
    "        while len(ivec) != prev_len:\n",
    "            prev_len = len(ivec)\n",
    "            ivec = polygroup.sindex.query(polygroup.geometry.iloc[ivec], predicate=\"intersects\")\n",
    "            ivec = np.unique(ivec[1, :])\n",
    "    \n",
    "        lbls = polygroup.index[ivec]\n",
    "        assert len(pot_reduce.loc[lbls].index.get_level_values(\"poly_id\").unique()) == 1\n",
    "        pot_reduce.loc[lbls, \"merge_group\"] = merge_group\n",
    "\n",
    "        for eid in lbls.get_level_values(\"edge_id\"):\n",
    "            edges_visited[eid] = True\n",
    "        merge_group += 1\n",
    "\n",
    "# Merge\n",
    "df_center_single_red = df_center_single[~df_center_single.index.isin(pot_reduce.index)].copy()\n",
    "add_rows = []\n",
    "for group_id, group in tqdm.tqdm(pot_reduce.groupby(\"merge_group\", dropna=True, sort=False), desc=\"merge edges\"):\n",
    "    edges_to_merge = np.unique(group.index.get_level_values(\"edge_id\").to_numpy())\n",
    "    geoms = df_center_single.geometry.loc[pd.IndexSlice[:, edges_to_merge]].tolist()\n",
    "    geom = shapely.ops.linemerge(geoms)\n",
    "    assert geom.geom_type == \"LineString\"\n",
    "    single_row = df_center_single.loc[pd.IndexSlice[:, edges_to_merge[0]], :].copy()\n",
    "    single_row.loc[:, \"geometry\"] = geom\n",
    "    add_rows.append(single_row)\n",
    "\n",
    "# Overwrite dataframes\n",
    "df_center_single = pd.concat([df_center_single_red] + add_rows)\n",
    "\n",
    "df_center_single_boundary = df_center_single.copy()\n",
    "df_center_single_boundary[\"geometry\"] = df_center_single.boundary\n",
    "\n",
    "df_center_single_boundary_points = df_center_single_boundary.explode(index_parts=True)\n",
    "df_center_single_boundary_points[\"node_id\"] = None\n",
    "idxs, node_ids = [], []\n",
    "for node_id, (geom, group) in enumerate(tqdm.tqdm(df_center_single_boundary_points.groupby(\"geometry\", sort=False), desc=\"assign node ids\")):\n",
    "    idxs.append(group.index)\n",
    "    node_ids.append(len(group) * [node_id])\n",
    "df_center_single_boundary_points.loc[np.hstack(idxs), \"node_id\"] = np.hstack(node_ids)\n",
    "assert not pd.isna(df_center_single_boundary_points.node_id).any()\n",
    "df_center_single_boundary_points = df_center_single_boundary_points.droplevel(-1).set_index(\"node_id\", append=True)\n",
    "\n",
    "# # Check of alles mooi verbonden is\n",
    "# for i, row in tqdm.tqdm(enumerate(df_center_single_boundary.itertuples()), total=len(df_center_single_boundary), desc=\"check connections\"):\n",
    "#     idx = row.Index\n",
    "#     geom = row.geometry\n",
    "\n",
    "#     idxs, dists = df_center_single_boundary.sindex.nearest(geom, return_distance=True, return_all=True)\n",
    "#     idxs = idxs[1, :]\n",
    "#     dists = dists[idxs != i]\n",
    "#     idxs = idxs[idxs != i]\n",
    "#     if dists.min() > 0:\n",
    "#         print(f\"no closed connection for {idx}, {dist.min()=}\")\n",
    "#     elif len(idxs) == 0:\n",
    "#         print(f\"No connection for {idx}: {df_center_single_boundary.iloc[idxs].index}\")\n",
    "\n",
    "df_center_single_boundary_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e1086-511c-477f-8173-6da9985e67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_lengths = dict(zip(df_center_single.index.get_level_values(\"edge_id\"), df_center_single.length))\n",
    "shortest_paths = {\"poly_id\": [], \"start_node\": [], \"end_node\": [], \"geometry\": []}\n",
    "for poly_id, row in tqdm.tqdm(df_merged.iterrows(), total=len(df_merged)):\n",
    "    merged_poly = row.geometry\n",
    "\n",
    "    globalids = df.globalid.loc[df.merged_poly_id == poly_id].unique()\n",
    "    df_crossings_single = df_crossings[df_crossings.peilgebied_from.isin(globalids) | df_crossings.peilgebied_to.isin(globalids)].copy()\n",
    "\n",
    "    # End point\n",
    "    df_graph = df_center_single_boundary_points.loc[pd.IndexSlice[poly_id, :, :], :].copy()\n",
    "    idx_end, distance_end = df_graph.sindex.nearest(merged_poly.representative_point(), return_distance=True, return_all=False)\n",
    "    distance_end = distance_end[0]\n",
    "    idx_end = idx_end[1,0]\n",
    "    idx_end = df_graph.index[idx_end]\n",
    "    end_node = idx_end[-1]\n",
    "    df_crossings\n",
    "    # print(f\"{poly_id=}, closest vertex for endpoint at {distance_end:.2f}m ({idx_end=})\")\n",
    "\n",
    "    # Starting points\n",
    "    idxs, distances = df_graph.sindex.nearest(df_crossings_single.geometry, return_distance=True, return_all=False)\n",
    "    idx_cross = df_crossings_single.iloc[idxs[0, :]].index\n",
    "    df_crossings_single.loc[idx_cross, \"start_node\"] = df_graph.iloc[idxs[1, :]].index.get_level_values(\"node_id\")\n",
    "    df_crossings.loc[idx_cross, \"start_node\"] = df_graph.iloc[idxs[1, :]].index.get_level_values(\"node_id\")\n",
    "    start_nodes = df_crossings_single[\"start_node\"].dropna().unique().astype(int).tolist()\n",
    "\n",
    "    # Make network for this polygon\n",
    "    node_ids = df_graph.index.get_level_values(\"node_id\")\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    # Add nodes and edges\n",
    "    graph.add_nodes_from(node_ids.unique().tolist())\n",
    "    for edge_id, group in df_graph.groupby(\"edge_id\", sort=False):\n",
    "        node1, node2 = group.index.get_level_values(\"node_id\").tolist()\n",
    "        graph.add_edge(node1, node2, weight=edge_lengths[edge_id])\n",
    "\n",
    "    # Determine shortest path for each start node\n",
    "    for start_node in tqdm.tqdm(start_nodes, leave=False, desc=f\"{poly_id=}\"):\n",
    "        try:\n",
    "            # node_path = nx.dijkstra_path(graph, start_node, end_node)\n",
    "            node_path = nx.astar_path(graph, start_node, end_node)\n",
    "            edges = df_graph.loc[pd.IndexSlice[:, :, node_path]].index.get_level_values(\"edge_id\").to_numpy()\n",
    "            geom = shapely.ops.linemerge(df_center_single.geometry.loc[pd.IndexSlice[poly_id, edges]].tolist())\n",
    "            shortest_paths[\"poly_id\"].append(poly_id)\n",
    "            shortest_paths[\"start_node\"].append(start_node)\n",
    "            shortest_paths[\"end_node\"].append(end_node)\n",
    "            shortest_paths[\"geometry\"].append(geom)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "df_startcrossings = df_crossings[~pd.isna(df_crossings.start_node)].copy()\n",
    "shortest_paths = gpd.GeoDataFrame(shortest_paths, geometry=\"geometry\", crs=df_crossings.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c5702-5b9c-4599-907f-74465ae09b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_file(\"test_voronoi.gpkg\", layer=\"merged_poly\")\n",
    "df_center_single.to_file(\"test_voronoi.gpkg\", layer=\"edges\")\n",
    "df_center_single_boundary_points.to_file(\"test_voronoi.gpkg\", layer=\"nodes\")\n",
    "shortest_paths.to_file(\"test_voronoi.gpkg\", layer=\"shortest_paths\")\n",
    "df_startcrossings.to_file(\"test_voronoi.gpkg\", layer=\"start_crossings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4e2be-66f5-4bfd-88f1-c9e0e7a1e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check of alles mooi verbonden is\n",
    "# for poly_id, polygroup in tqdm.tqdm(df_center_single_boundary.groupby(\"poly_id\", sort=False), desc=\"check connections\"):\n",
    "#     for i, row in enumerate(polygroup.itertuples()):\n",
    "#         idx = row.Index\n",
    "#         geom = row.geometry\n",
    "    \n",
    "#         idxs = polygroup.sindex.query(geom, predicate=\"intersects\")\n",
    "#         idxs = idxs[idxs != i]\n",
    "#         dists = polygroup.geometry.iloc[idxs].distance(row.geometry)\n",
    "#         if dists.min() > 0:\n",
    "#             print(f\"no closed connection for {idx}, {dist.min()=}\")\n",
    "#         if len(idxs) == 0:\n",
    "#             print(f\"No connection for {idx}: {polygroup.iloc[idxs].index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42deff-1761-4489-bab6-b2f99fa37093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ribasim]",
   "language": "python",
   "name": "conda-env-ribasim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

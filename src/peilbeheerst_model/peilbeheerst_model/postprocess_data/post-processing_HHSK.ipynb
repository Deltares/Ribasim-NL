{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# HHSK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This script adds a new column \"peilgebied_cat\" and make sure the peilgebieden allign witgh the HWS layer (Daniel):\n",
    "- peilgebied_cat = 0 -> peilgebied\n",
    "- peigelbied_cat = 1 -> RHWS (boezem)\n",
    "- peilgebied_cat = 2 -> NHWS Notes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from general_functions import read_gpkg_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## HHSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relative paths\n",
    "waterschap = \"HHSK\"\n",
    "\n",
    "data_path = f\"../projects/4750_20/Data_postprocessed/Waterschappen/{waterschap}/{waterschap}.gpkg\"\n",
    "\n",
    "# Waterschaps boundaries\n",
    "grens_path = \"../projects/4750_30/Data_overig/Waterschapsgrenzen/Waterschapsgrenzen.geojson\"\n",
    "# Hoofdwatersysteem boundaries\n",
    "hws_path = \"../projects/4750_30/Data_overig/HWS/krw_basins_vlakken.gpkg\"\n",
    "# Buffer boundaries\n",
    "buffer_path = \"../projects/4750_30/Data_overig/HWS/hws_buffer_HHSK.gpkg\"\n",
    "# Output folder\n",
    "output_folder = f\"./Waterschappen/{waterschap}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HHNK files\n",
    "HHSK = read_gpkg_layers(\n",
    "    gpkg_path=data_path,\n",
    "    variables=[\n",
    "        \"stuw\",\n",
    "        \"gemaal\",\n",
    "        \"hydroobject\",\n",
    "        \"duikersifonhevel\",\n",
    "        \"peilgebied\",\n",
    "        \"streefpeil\",\n",
    "    ],\n",
    ")\n",
    "HHSK[\"peilgebied\"] = HHSK[\"peilgebied\"].to_crs(\"EPSG:28992\")\n",
    "\n",
    "# Load waterschap boundaries\n",
    "gdf_grens = gpd.read_file(grens_path)\n",
    "gdf_grens = gdf_grens.to_crs(\"EPSG:28992\")\n",
    "gdf_grens = gdf_grens.set_index(\"waterschap\")\n",
    "\n",
    "# Load hws\n",
    "gdf_hws = gpd.read_file(hws_path)\n",
    "\n",
    "# Load buffer\n",
    "gdf_buffer = gpd.read_file(buffer_path)\n",
    "gdf_buffer = gdf_buffer.to_crs(\"EPSG:28992\")\n",
    "gdf_buffer = gdf_buffer.dissolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Select waterschap boundaries and clip hws layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select boundaries HH Amstel, Gooi en Vecht\n",
    "gdf_grens = gdf_grens.loc[[\"Schieland en de Krimpenerwaard\"]]\n",
    "\n",
    "# Use waterschap boudnaries to clip HWS layer\n",
    "gdf_hws = gpd.overlay(gdf_grens, gdf_hws, how=\"intersection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Check Peilgebied and HWS layer overlap:\n",
    "1. Identify the overlapping areas\n",
    "2. Clip\n",
    "3. Calculate overlapping area percentage\n",
    "4. Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify the Overlapping Areas and clip\n",
    "overlaps = gpd.overlay(HHSK[\"peilgebied\"], gdf_hws, how=\"intersection\", keep_geom_type=True)\n",
    "gdf_hws = gpd.overlay(gdf_hws, HHSK[\"peilgebied\"], how=\"difference\")\n",
    "\n",
    "# # Step 2: Subtract Overlapping Areas from the original polygons in each DataFrame\n",
    "non_overlapping_peilgebied = gpd.overlay(HHSK[\"peilgebied\"], overlaps, how=\"difference\", keep_geom_type=True)\n",
    "overlaps = gpd.overlay(non_overlapping_peilgebied, gdf_hws, how=\"intersection\", keep_geom_type=False)\n",
    "\n",
    "# Step 3: Calculate Area Percentages\n",
    "# Calculate the area of overlaps\n",
    "overlaps[\"overlap_area\"] = overlaps.area\n",
    "\n",
    "# Step 4: Filter based on area Area Percentages\n",
    "minimum_area = 50\n",
    "print(f\"Number of overlapping shapes without filter: {len(overlaps)}\")\n",
    "overlap_ids = overlaps.loc[overlaps[\"overlap_area\"] > minimum_area]\n",
    "overlap_ids = overlap_ids.globalid.to_list()\n",
    "print(f\"Number of overlapping shapes with filter: {len(overlap_ids)}\")\n",
    "\n",
    "# gdf_hws = gdf_hws_clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Create peilgebied_cat column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to geodataframe\n",
    "peilgebieden_cat = []\n",
    "\n",
    "for index, row in HHSK[\"peilgebied\"].iterrows():\n",
    "    if row.code == \"GPG-399\":\n",
    "        peilgebieden_cat.append(1)\n",
    "    elif row.code == \"GPG-403\":\n",
    "        peilgebieden_cat.append(1)\n",
    "    elif row.code == \"GPG-144_RV1\":\n",
    "        peilgebieden_cat.append(1)\n",
    "    elif row.code == \"GPG-144_RV2\":\n",
    "        peilgebieden_cat.append(1)\n",
    "    elif row.code == \"GPG-144_RV3\":\n",
    "        peilgebieden_cat.append(1)\n",
    "\n",
    "    else:\n",
    "        peilgebieden_cat.append(0)\n",
    "\n",
    "HHSK[\"peilgebied\"][\"peilgebied_cat\"] = peilgebieden_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Add nhws to ['peilgebied','streefpeil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update peilgebied dict key\n",
    "gdf_hws[\"globalid\"] = \"dummy_globalid_nhws_\" + gdf_hws.index.astype(str)\n",
    "gdf_hws[\"code\"] = \"dummy_code_nhws_\" + gdf_hws.index.astype(str)\n",
    "gdf_hws[\"nen3610id\"] = \"dummy_nen3610id_nhws_\" + gdf_hws.index.astype(str)\n",
    "gdf_hws[\"peilgebied_cat\"] = 2\n",
    "\n",
    "gdf_hws = gdf_hws[[\"globalid\", \"code\", \"nen3610id\", \"peilgebied_cat\", \"geometry\"]]\n",
    "\n",
    "HHSK[\"peilgebied\"] = pd.concat([gdf_hws, HHSK[\"peilgebied\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update streefpeil dict key\n",
    "streefpeil_hws = pd.DataFrame()\n",
    "streefpeil_hws[\"waterhoogte\"] = [np.nan] * len(gdf_hws)\n",
    "streefpeil_hws[\"globalid\"] = \"dummy_globalid_nhws_\" + gdf_hws.index.astype(str)\n",
    "streefpeil_hws[\"geometry\"] = [None] * len(gdf_hws)\n",
    "\n",
    "HHSK[\"streefpeil\"] = pd.concat([streefpeil_hws, HHSK[\"streefpeil\"]])\n",
    "HHSK[\"streefpeil\"] = gpd.GeoDataFrame(HHSK[\"streefpeil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Create buffer polygon between NHWS and peilgebied/RHWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_polygon = gdf_buffer.geometry.iat[0].intersection(gdf_grens.geometry.iat[0])\n",
    "buffer_polygon = buffer_polygon.difference(shapely.geometry.MultiPolygon(gdf_hws.geometry.tolist()))\n",
    "buffer_polygon = buffer_polygon.difference(shapely.ops.unary_union(HHSK[\"peilgebied\"].geometry.tolist()))\n",
    "\n",
    "buffer_polygon = gpd.GeoDataFrame(buffer_polygon)\n",
    "buffer_polygon = buffer_polygon.set_geometry(0)\n",
    "buffer_polygon = buffer_polygon.dissolve()\n",
    "buffer_polygon = buffer_polygon.rename(columns={0: \"geometry\"})\n",
    "buffer_polygon = buffer_polygon.set_geometry(\"geometry\")\n",
    "buffer_polygon = buffer_polygon.set_crs(\"EPSG:28992\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Add buffer to ['peilgebied','streefpeil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update peilgebied dict key\n",
    "buffer_polygon = gpd.GeoDataFrame(buffer_polygon)\n",
    "buffer_polygon[\"globalid\"] = \"dummy_globalid_nhws_buffer_\" + \"1\"\n",
    "buffer_polygon[\"code\"] = \"dummy_code_nhws_buffer_\" + buffer_polygon.index.astype(str)\n",
    "buffer_polygon[\"nen3610id\"] = \"dummy_nen3610id_nhws_buffer_\" + buffer_polygon.index.astype(str)\n",
    "buffer_polygon[\"peilgebied_cat\"] = 2\n",
    "buffer_polygon = buffer_polygon.rename(columns={0: \"geometry\"})\n",
    "buffer_polygon = buffer_polygon[[\"globalid\", \"code\", \"nen3610id\", \"peilgebied_cat\", \"geometry\"]]\n",
    "\n",
    "HHSK[\"peilgebied\"] = pd.concat([buffer_polygon, HHSK[\"peilgebied\"]])\n",
    "HHSK[\"peilgebied\"] = gpd.GeoDataFrame(HHSK[\"peilgebied\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boezem streefpeil layer\n",
    "streefpeil_buffer = pd.DataFrame()\n",
    "streefpeil_buffer[\"waterhoogte\"] = [np.nan]\n",
    "streefpeil_buffer[\"globalid\"] = [\"dummy_globalid_nhws_buffer_1\"]\n",
    "streefpeil_buffer[\"geometry\"] = [None]\n",
    "\n",
    "\n",
    "HHSK[\"streefpeil\"] = pd.concat([streefpeil_buffer, HHSK[\"streefpeil\"]])\n",
    "HHSK[\"streefpeil\"] = gpd.GeoDataFrame(HHSK[\"streefpeil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Fix duplicates hydroobjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename duplicates\n",
    "# identify duplicates\n",
    "HHSK[\"hydroobject\"][\"temp_globalid\"] = HHSK[\"hydroobject\"].groupby(\"globalid\").cumcount() + 1\n",
    "HHSK[\"hydroobject\"][\"temp_code\"] = HHSK[\"hydroobject\"].groupby(\"code\").cumcount() + 1\n",
    "HHSK[\"hydroobject\"][\"temp_nen3610id\"] = HHSK[\"hydroobject\"].groupby(\"nen3610id\").cumcount() + 1\n",
    "\n",
    "# AAdd _1 etc\n",
    "HHSK[\"hydroobject\"][\"globalid_new\"] = HHSK[\"hydroobject\"].apply(\n",
    "    lambda x: f\"{x['globalid']}_{x['temp_globalid']}\" if x[\"temp_globalid\"] > 1 else x[\"globalid\"], axis=1\n",
    ")\n",
    "HHSK[\"hydroobject\"][\"code_new\"] = HHSK[\"hydroobject\"].apply(\n",
    "    lambda x: f\"{x['code']}_{x['temp_code']}\" if x[\"temp_code\"] > 1 else x[\"code\"], axis=1\n",
    ")\n",
    "HHSK[\"hydroobject\"][\"nen3610id_new\"] = HHSK[\"hydroobject\"].apply(\n",
    "    lambda x: f\"{x['nen3610id']}_{x['temp_nen3610id']}\" if x[\"temp_nen3610id\"] > 1 else x[\"nen3610id\"], axis=1\n",
    ")\n",
    "\n",
    "# drop columns\n",
    "HHSK[\"hydroobject\"] = HHSK[\"hydroobject\"].drop(\n",
    "    columns=[\"temp_globalid\", \"temp_code\", \"temp_nen3610id\", \"globalid\", \"nen3610id\", \"code\"]\n",
    ")\n",
    "# rename columns\n",
    "HHSK[\"hydroobject\"] = HHSK[\"hydroobject\"].rename(\n",
    "    columns={\"globalid_new\": \"globalid\", \"code_new\": \"code\", \"nen3610id_new\": \"nen3610id\"}\n",
    ")\n",
    "# check\n",
    "print(HHSK[\"hydroobject\"].globalid.is_unique)\n",
    "print(HHSK[\"hydroobject\"].code.is_unique)\n",
    "print(HHSK[\"hydroobject\"].nen3610id.is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Store post-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in HHSK.keys():\n",
    "    print(key)\n",
    "    HHSK[str(key)].to_file(f\"{output_folder}/{waterschap}.gpkg\", layer=str(key), driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stable]",
   "language": "python",
   "name": "conda-env-stable-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

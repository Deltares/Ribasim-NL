{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924705f1-1daf-4219-88d9-21fab4b99cff",
   "metadata": {},
   "source": [
    "# Rijnland\n",
    "\n",
    "\n",
    "### Create shortest_path RHWS network\n",
    "\n",
    "Code is based on: https://github.com/Deltares/Ribasim-NL/blob/1ad35931f49280fe223cbd9409e321953932a3a4/notebooks/ijsselmeermodel/netwerk.py#L55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af9481d-973d-4984-ab7f-49c1aaf3360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import fiona\n",
    "import tqdm.auto as tqdm\n",
    "import shapely\n",
    "from shapely.geometry import LineString, Point,MultiPoint,MultiLineString,Polygon\n",
    "from shapely.ops import split, nearest_points\n",
    "from shapely.wkt import dumps\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc03b1-cdd1-422b-bdba-009e9722b6b1",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0803592-1a07-461d-9432-937520958dbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/DATAFOLDER/projects/4750_30/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load crossings file\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m DATA \u001b[38;5;241m=\u001b[39m {L: gpd\u001b[38;5;241m.\u001b[39mread_file(data_path, layer\u001b[38;5;241m=\u001b[39mL) \u001b[38;5;28;01mfor\u001b[39;00m L \u001b[38;5;129;01min\u001b[39;00m fiona\u001b[38;5;241m.\u001b[39mlistlayers(data_path)}\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/DATAFOLDER/projects/4750_30/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load crossings file\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m DATA \u001b[38;5;241m=\u001b[39m {L: \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m L \u001b[38;5;129;01min\u001b[39;00m fiona\u001b[38;5;241m.\u001b[39mlistlayers(data_path)}\n",
      "File \u001b[0;32m/opt/tljh/user/envs/ribasim/lib/python3.10/site-packages/geopandas/io/file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/ribasim/lib/python3.10/site-packages/geopandas/io/file.py:395\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m    392\u001b[0m         [record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m f_filt], columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    393\u001b[0m     )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mGeoDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf_filt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m datetime_fields:\n\u001b[1;32m    399\u001b[0m     as_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/ribasim/lib/python3.10/site-packages/geopandas/geodataframe.py:636\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    633\u001b[0m     features_lst \u001b[38;5;241m=\u001b[39m features\n\u001b[1;32m    635\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features_lst:\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;66;03m# load geometry\u001b[39;00m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__geo_interface__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    639\u001b[0m         feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39m__geo_interface__\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1743\u001b[0m, in \u001b[0;36mfiona.ogrext.Iterator.__next__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/ribasim/lib/python3.10/site-packages/fiona/collection.py:277\u001b[0m, in \u001b[0;36mCollection.driver\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_drivers[driver]:\n\u001b[1;32m    275\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DriverError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported mode: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdriver\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the name of the proper OGR driver.\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driver \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "waterschap = \"Rijnland\"\n",
    "\n",
    "# Define crossings file path\n",
    "path2json = \"/DATAFOLDER/projects/4750_30/Scripts/Ribasim-NL/src/peilbeheerst_model/waterschappen.json\"\n",
    "data_path_str = pd.read_json(path2json).loc['init'][waterschap]['output_path']\n",
    "data_path = f\"/DATAFOLDER/projects/4750_30/{data_path_str.split('../')[-1]}\"\n",
    "\n",
    "# Load crossings file\n",
    "DATA = {L: gpd.read_file(data_path, layer=L) for L in fiona.listlayers(data_path)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51000003-77ac-4227-8d51-3845b7755d22",
   "metadata": {},
   "source": [
    "### Select rhws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e1f8b-6c3b-473b-92ef-79f81973960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select RHWS peilgebeied & calculate representative point\n",
    "gdf_rhws = DATA[\"peilgebied\"].loc[DATA[\"peilgebied\"][\"peilgebied_cat\"] == 1].copy()\n",
    "gdf_rhws[\"representative_point\"] = gdf_rhws.representative_point()\n",
    "\n",
    "# Apply aggregation level based filter\n",
    "gdf_cross = DATA[\"crossings_hydroobject_filtered\"].loc[DATA[\"crossings_hydroobject_filtered\"][\"agg_links_in_use\"]].copy() # filter aggregation level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2d0fe-6649-4368-8a83-c1e177fc34f7",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "1. splitting functions\n",
    "2. connect graphs functions\n",
    "3. explode nodes functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653be271-3e5d-4d57-a8eb-65bc8b128e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line_at_point(line, point):\n",
    "    buff = point.buffer(1e-4)  # Small buffer around the point\n",
    "    split_result = split(line, buff)\n",
    "    if len(split_result.geoms) in [2, 3]:\n",
    "        # Assume first and last segments are the result, ignore tiny middle segment if exists\n",
    "        result = MultiLineString([split_result.geoms[0], split_result.geoms[-1]])\n",
    "    else:\n",
    "        # Return the original line as a MultiLineString for consistency if no split occurred\n",
    "        result = MultiLineString([line])\n",
    "    return result\n",
    "\n",
    "def split_lines_at_intersections(gdf_object):\n",
    "    split_lines = []\n",
    "    attributes = gdf_object.drop(columns=['geometry'])  # Preserve non-geometry attributes\n",
    "\n",
    "    for idx, row in gdf_object.iterrows():\n",
    "        was_split = False\n",
    "\n",
    "        # Get potential intersections using spatial index\n",
    "        possible_matches_index = list(gdf_object.sindex.intersection(row.geometry.bounds))\n",
    "        possible_matches = gdf_object.iloc[possible_matches_index].drop(idx)  # Exclude self\n",
    "        precise_matches = possible_matches[possible_matches.intersects(row.geometry)]\n",
    "        \n",
    "        for match_idx, match in precise_matches.iterrows():\n",
    "            if row.geometry.intersects(match.geometry):\n",
    "                intersection = row.geometry.intersection(match.geometry)\n",
    "                if isinstance(intersection, Point):\n",
    "                    # Split the current line at the intersection point\n",
    "                    try:\n",
    "                        split_result = split_line_at_point(row.geometry, intersection)\n",
    "                        for geom in split_result.geoms:\n",
    "                            new_row = row.copy()\n",
    "                            new_row.geometry = geom\n",
    "                            split_lines.append(new_row)\n",
    "                        was_split = True\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error splitting line: {e}\")\n",
    "                # Add other intersection types handling if needed\n",
    "                break  # Assumes only one split per line; remove or modify for multiple splits\n",
    "\n",
    "        if not was_split:\n",
    "            # If the line was not split, include the original line\n",
    "            split_lines.append(row)\n",
    "\n",
    "    # Create a new GeoDataFrame from the split or original lines\n",
    "    result_gdf = gpd.GeoDataFrame(split_lines, columns=gdf_object.columns)\n",
    "    return result_gdf\n",
    "\n",
    "def component_to_gdf(component, node_geometries):\n",
    "    geometries = [node_geometries[node] for node in component]\n",
    "    return gpd.GeoDataFrame(geometry=geometries, index=list(component))\n",
    "\n",
    "def connect_components(graph, node1, node2, node_geometries):\n",
    "    geom1 = node_geometries[node1]\n",
    "    geom2 = node_geometries[node2]\n",
    "    new_edge_geom = LineString([geom1.coords[0], geom2.coords[0]])\n",
    "    graph.add_edge(node1, node2, geometry=new_edge_geom)\n",
    "    \n",
    "def find_closest_component_pair(largest_gdf, smaller_gdfs):\n",
    "    print(len(smaller_gdfs), end='\\r')\n",
    "    sgdf = gpd.GeoSeries([shapely.geometry.MultiPoint(small_gdf.geometry.tolist()) for small_gdf in smaller_gdfs])\n",
    "    nearest_i, dist2 = sgdf.sindex.nearest(largest_gdf.geometry, return_all=False, return_distance=True)\n",
    "    li, si = nearest_i[:, np.argmin(dist2)]\n",
    "    \n",
    "    nearest_idx, dist = smaller_gdfs[si].sindex.nearest(largest_gdf.geometry.iat[li], return_all=False, return_distance=True)\n",
    "    node_in_smaller = smaller_gdfs[si].index[nearest_idx[1,0]]\n",
    "    node_in_largest = largest_gdf.index[li]\n",
    "    closest_pair_nodes = (node_in_largest, node_in_smaller)\n",
    "    # print(\"done\") \n",
    "    return si, closest_pair_nodes\n",
    "\n",
    "\n",
    "def cut_linestring_at_interval(line, interval):\n",
    "    \"\"\"Cut a LineString into segments of a specified interval.\"\"\"\n",
    "    # Calculate the number of segments needed\n",
    "    num_segments = int(np.ceil(line.length / interval))\n",
    "    if num_segments == 1:\n",
    "        return [line]\n",
    "\n",
    "    points = [line.interpolate(distance) for distance in np.linspace(0, line.length, num_segments + 1)]\n",
    "    return [LineString([points[i], points[i+1]]) for i in range(num_segments)]\n",
    "\n",
    "def explode_linestrings(gdf, interval):\n",
    "    \"\"\"Explode LineStrings in a GeoDataFrame into smaller segments based on a distance interval.\"\"\"\n",
    "    segments = []\n",
    "    for _, row in gdf.iterrows():\n",
    "        line = row.geometry\n",
    "        segments.extend(cut_linestring_at_interval(line, interval))\n",
    "\n",
    "    return gpd.GeoDataFrame(geometry=segments, crs=gdf.crs)\n",
    "\n",
    "\n",
    "def connect_linestrings_within_distance(gdf, max_distance=4):\n",
    "\n",
    "        gdf = gdf.explode(ignore_index=False, index_parts=True)\n",
    "        gdf[\"geometry\"] = gdf.make_valid()\n",
    "        gdf[\"geometry\"] = gdf.geometry.apply(shapely.force_2d)\n",
    "        gdf = gdf[~gdf.is_empty].copy()\n",
    "\n",
    "        change_idx, change_geom = [], []\n",
    "        for row in tqdm.tqdm(\n",
    "            gdf.itertuples(),\n",
    "            total=len(gdf),\n",
    "        ):\n",
    "            ps = row.geometry.boundary.geoms\n",
    "            if len(ps) != 2:\n",
    "                continue\n",
    "            p0, p1 = ps\n",
    "\n",
    "            p0_changed, p1_changed = False, False\n",
    "            idx0 = gdf.sindex.query(p0.buffer(max_distance), predicate=\"intersects\")\n",
    "            if len(idx0) > 0:\n",
    "                dist0 = gdf.iloc[idx0].distance(p0)\n",
    "                if (dist0 > 10E-8).any():\n",
    "                    snap_lbl0 = dist0[dist0 > 10E-8].idxmin()\n",
    "                    geom = gdf.geometry.at[snap_lbl0]\n",
    "                    p0 = geom.interpolate(geom.project(p0))\n",
    "                    p0_changed = True\n",
    "\n",
    "            idx1 = gdf.sindex.query(p1.buffer(max_distance), predicate=\"intersects\")\n",
    "            if len(idx1) > 0:\n",
    "                dist1 = gdf.iloc[idx1].distance(p1)\n",
    "                if (dist1 > 10E-8).any():\n",
    "                    snap_lbl1 = dist1[dist1 > 10E-8].idxmin()\n",
    "                    geom = gdf.geometry.at[snap_lbl1]\n",
    "                    p1 = geom.interpolate(geom.project(p1))\n",
    "                    p1_changed = True\n",
    "\n",
    "            if p0_changed or p1_changed:\n",
    "                coords = list(row.geometry.coords)\n",
    "                if p0_changed:\n",
    "                    coords = list(p0.coords) + coords\n",
    "                if p1_changed:\n",
    "                    coords = coords + list(p1.coords)\n",
    "                change_idx.append(row.Index)\n",
    "                change_geom.append(LineString(coords))\n",
    "\n",
    "        if len(change_idx) > 0:\n",
    "            gdf.loc[change_idx, \"geometry\"] = change_geom\n",
    "\n",
    "        return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb73d3-eea9-4a88-804a-ac35671bf75f",
   "metadata": {},
   "source": [
    "# Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d671b-e467-455b-993f-81269838270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_crossings_out = []\n",
    "gdf_rhws = gdf_rhws.reset_index(drop=True)\n",
    "\n",
    "# Loop RHWS polygons\n",
    "gdf_crossings_out = []\n",
    "\n",
    "\n",
    "for index, rhws in tqdm.tqdm(gdf_rhws.iterrows(), total=len(gdf_rhws), colour='blue'):\n",
    "\n",
    "    try:\n",
    "        print(index)\n",
    "        \n",
    "        ### Select Crossings/Hydroobjects ###\n",
    "        print(\"Select Crossings/Hydroobjects\")\n",
    "        \n",
    "        # Single RHWS row as GeoDataFrame\n",
    "        gdf_rhws_single = gpd.GeoDataFrame(rhws.to_frame().T, geometry=\"geometry\", crs=gdf_rhws.crs)\n",
    "        \n",
    "        # Select for each boezem polygon the relevant crossings\n",
    "        globalid_value = gdf_rhws_single.globalid.iloc[0]\n",
    "        gdf_cross_single = gdf_cross[(gdf_cross.peilgebied_from == globalid_value) | (gdf_cross.peilgebied_to == globalid_value)].copy()\n",
    "        print(\"Clip Crossings/Hydroobjects\")\n",
    "        # Select hydroobjects in RHWS polygons\n",
    "        gdf_object = gpd.clip(DATA[\"hydroobject\"], gdf_rhws_single)\n",
    "        gdf_object = gdf_object.reset_index(drop=True)\n",
    "        \n",
    "        # Explode linestrings\n",
    "        gdf_object = gdf_object.explode(index_parts=False).reset_index(drop=True)\n",
    "        gdf_object = gdf_object[~gdf_object.is_empty].copy()\n",
    "        gdf_object = gdf_object[gdf_object.length > 1e-7].copy()\n",
    "        print(\"Split Hydroobjects at Intersect\")\n",
    "        # Split lines at intersection\n",
    "        gdf_object = split_lines_at_intersections(gdf_object)\n",
    "        \n",
    "        print(\"Connect Hydroobjects within distance\")\n",
    "        # Explode the linestrings into smaller segments\n",
    "        distance_interval = 50  # The distance interval you want to segment the lines at\n",
    "        gdf_object = explode_linestrings(gdf_object, distance_interval)\n",
    "        \n",
    "        # Make sure that hydroobjects are connected\n",
    "        gdf_object = connect_linestrings_within_distance(gdf_object)\n",
    "        \n",
    "        # Explode linestrings\n",
    "        gdf_object = gdf_object.explode(index_parts=False).reset_index(drop=True)\n",
    "        gdf_object = gdf_object[~gdf_object.is_empty].copy()\n",
    "        gdf_object = gdf_object[gdf_object.length > 1e-7].copy()\n",
    "        \n",
    "        \n",
    "        ### Create NetworkX nodes ###\n",
    "        print(\"Create NetworkX\")\n",
    "        # Use start and end points from hydroobjects in networkx as nodes\n",
    "        nodes_gdf = gdf_object.copy()\n",
    "        nodes_gdf[\"geometry\"] = nodes_gdf.geometry.boundary\n",
    "        nodes_gdf = nodes_gdf.explode(index_parts=True)\n",
    "        \n",
    "        # Use the unique points as nodes in networkx\n",
    "        nodes_gdf.insert(0, \"node_id\", -1)\n",
    "        node_id = 1\n",
    "        for geom, group in nodes_gdf.groupby(\"geometry\"):\n",
    "            nodes_gdf.loc[group.index, \"node_id\"] = node_id\n",
    "            node_id += 1\n",
    "            \n",
    "        ### Select startpoints & endpoints RHWS network ###\n",
    "        # Find the closest starting points from the crossings.\n",
    "        # Keep only points which are (almost) equal to the crossings.\n",
    "        startpoints, distances = nodes_gdf.sindex.nearest(gdf_cross_single.geometry, return_all=False, return_distance=True)\n",
    "        startpoints = nodes_gdf.node_id.iloc[startpoints[1,:]].values\n",
    "        \n",
    "        gdf_cross_single[\"node_id\"] = startpoints\n",
    "        gdf_cross_single[\"node_id_distance\"] = distances\n",
    "        \n",
    "        # find the node_id closest to the RHWS representative point (end point)\n",
    "        # Exclude the points which are already used as starting points\n",
    "        df_endpoint = nodes_gdf[~nodes_gdf.node_id.isin(gdf_cross_single.node_id)].copy()\n",
    "        endpoint, distance = df_endpoint.sindex.nearest(rhws.representative_point, return_all=False, return_distance=True)\n",
    "        \n",
    "        endpoint = df_endpoint.node_id.iat[endpoint[1,0]]\n",
    "        gdf_rhws_single[\"node_id\"] = endpoint\n",
    "        gdf_rhws_single[\"node_id_distance\"] = distance\n",
    "\n",
    "\n",
    "        \n",
    "        ### Create networkx graph ###\n",
    "        graph = nx.Graph()\n",
    "        \n",
    "        # add nodes in boezem\n",
    "        for node_id, group in nodes_gdf.groupby(\"node_id\"):\n",
    "            graph.add_node(node_id, geometry=group.geometry.iat[0])\n",
    "        \n",
    "        # add edges\n",
    "        line_lookup = gdf_object.geometry\n",
    "        for idx0, group in nodes_gdf.groupby(level=0):\n",
    "            node_from, node_to = group.node_id\n",
    "            line_geom = gdf_object.geometry.at[idx0]\n",
    "            graph.add_edge(node_from, node_to, length=line_geom.length, geometry=line_geom)\n",
    "        \n",
    "        ### Find distruptions Graph ###\n",
    "        # The graph often consists of multiple smaller graphs due to edges not properly connecting with nodes\n",
    "        # Get lists of compnents (sub-graph)  \n",
    "        print(\"Find distruptions in Graph\")\n",
    "        components = list(nx.connected_components(graph))\n",
    "        largest_component = max(components, key=len) \n",
    "        smaller_components = [comp for comp in components if comp != largest_component] # not used anymore\n",
    "        print(len(smaller_components), end=\"\\r\")\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            components = list(nx.connected_components(graph))\n",
    "            largest_component = max(components, key=len)\n",
    "            smaller_components = [comp for comp in components if comp != largest_component]\n",
    "            \n",
    "            if not smaller_components:  # If there are no smaller components left, break the loop\n",
    "                break\n",
    "                \n",
    "            print(len(smaller_components), end='\\r')\n",
    "            # Update node geometries and largest_gdf for each iteration\n",
    "            node_geometries = {node: graph.nodes[node]['geometry'] for node in graph.nodes()}\n",
    "            largest_gdf = component_to_gdf(largest_component, node_geometries)\n",
    "            smaller_gdfs = [component_to_gdf(comp, node_geometries) for comp in smaller_components]\n",
    "            \n",
    "            # Find the closest smaller_gdf to the largest_gdf\n",
    "            closest_index, (node_in_largest, node_in_smaller) = find_closest_component_pair(largest_gdf, smaller_gdfs)\n",
    "            \n",
    "            # Connect the closest nodes\n",
    "            connect_components(graph, node_in_largest, node_in_smaller, node_geometries)\n",
    "           \n",
    "        # calculate shortest_path networkx\n",
    "        gdf_cross_single[\"shortest_path\"] = shapely.geometry.GeometryCollection()\n",
    "        not_connected = []\n",
    "        \n",
    "        components = list(nx.connected_components(graph))\n",
    "        largest_component = max(components, key=len) \n",
    "        smaller_components = [comp for comp in components if comp != largest_component]\n",
    "        node_geometries = {node: graph.nodes[node]['geometry'] for node in graph.nodes()}\n",
    "        \n",
    "        for startpoint in startpoints:\n",
    "            try:\n",
    "                shortest_path = nx.shortest_path(graph, source=startpoint, target=endpoint, weight=\"length\", method=\"dijkstra\")\n",
    "                edges = []\n",
    "                for i in range(0, len(shortest_path)-1):\n",
    "                    edges.append(graph.get_edge_data(shortest_path[i], shortest_path[i+1])[\"geometry\"])\n",
    "                gdf_cross_single.loc[gdf_cross_single.node_id == startpoint, \"shortest_path\"] = shapely.ops.linemerge(edges)\n",
    "        \n",
    "            except nx.NetworkXNoPath as e:\n",
    "                print(e)\n",
    "                not_connected.append(startpoint)\n",
    "                \n",
    "        if not_connected:\n",
    "            print(\"not connected\")\n",
    "            # Force connection\n",
    "            # Convert the largest connected component to a GeoDataFrame for spatial operations\n",
    "            largest_component_gdf = gpd.GeoDataFrame(geometry=[node_geometries[node] for node in largest_component], crs=gdf_rhws.crs)\n",
    "            largest_component_gdf['node_id'] = list(largest_component)\n",
    "        \n",
    "            # Iterate over each not_connected node\n",
    "            for nc_node in not_connected:\n",
    "                nc_node_geom = node_geometries[nc_node]\n",
    "        \n",
    "                # Calculate the distance to all nodes in the largest component\n",
    "                distances = largest_component_gdf.geometry.distance(nc_node_geom)\n",
    "        \n",
    "                # Find the closest node in the largest component\n",
    "                closest_node_id = largest_component_gdf.iloc[distances.idxmin()].node_id\n",
    "        \n",
    "                # Add edge between not_connected node and closest node in the largest component\n",
    "                # Note: You might want to calculate the LineString geometry connecting these nodes based on your specific requirements\n",
    "                graph.add_edge(nc_node, closest_node_id, geometry=LineString([node_geometries[nc_node], node_geometries[closest_node_id]]))\n",
    "        \n",
    "            for startpoint in startpoints:\n",
    "                try:\n",
    "                    shortest_path = nx.shortest_path(graph, source=startpoint, target=endpoint, weight=\"length\", method=\"dijkstra\")\n",
    "                    edges = []\n",
    "                    for i in range(0, len(shortest_path)-1):\n",
    "                        edges.append(graph.get_edge_data(shortest_path[i], shortest_path[i+1])[\"geometry\"])\n",
    "                    gdf_cross_single.loc[gdf_cross_single.node_id == startpoint, \"shortest_path\"] = shapely.ops.linemerge(edges)\n",
    "        \n",
    "                except nx.NetworkXNoPath as e:\n",
    "                    print(e)\n",
    "                    not_connected.append(startpoint)\n",
    "        \n",
    "        ### Append output ###\n",
    "        gdf_crossings_out.append(gdf_cross_single)\n",
    "        \n",
    "        \n",
    "        ### Plot graph ###\n",
    "        print(\"Plotting Output\")\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        plt_paths = gpd.GeoDataFrame(gdf_cross_single, geometry=\"shortest_path\", crs=gdf_cross_single.crs)\n",
    "        plt_rep = gpd.GeoDataFrame(gdf_rhws_single, geometry=\"representative_point\", crs=gdf_rhws_single.crs)\n",
    "        plt_rhws = gpd.GeoDataFrame(gdf_rhws_single, geometry=\"geometry\", crs=gdf_rhws_single.crs)\n",
    "        ax.set_title(f\"{waterschap} shortest paths {index}\")\n",
    "        plt_rhws.plot(ax=ax,color='green')\n",
    "        gdf_rhws_single.plot(ax=ax, color=\"lightblue\")\n",
    "        plt_rep.plot(ax=ax, color=\"blue\", label=\"representative_point\")\n",
    "        gdf_object.plot(ax=ax, color=\"gray\", linewidth=0.5, label=\"hydroobjects\")\n",
    "        gdf_cross_single.plot(ax=ax, color=\"orange\", label=\"crossings\")\n",
    "        plt_paths.plot(ax=ax, color=\"purple\", label=\"shortest paths\")\n",
    "        ax.legend()\n",
    "        plt.savefig(f\"./shortest_path/Figures/shortest_path_{waterschap}_RHWS_{index}_new\", dpi=300)\n",
    "        \n",
    "        # Save results\n",
    "        print(\"Writing Output\")\n",
    "        objects = {}\n",
    "        objects['hydroobjects'] = gpd.GeoDataFrame(gdf_object, geometry=\"geometry\", crs=gdf_cross_single.crs)    \n",
    "        shortest_path = gdf_cross_single.drop(columns=['geometry'])\n",
    "        shortest_path = shortest_path.rename(columns={'shortest_path':'geometry'})                                       \n",
    "        shortest_path = gpd.GeoDataFrame(shortest_path, geometry=\"geometry\", crs=gdf_cross_single.crs)\n",
    "        shortest_path[\"geometry\"] = shortest_path.apply(lambda r: shapely.simplify(r.geometry, tolerance=1, preserve_topology=True), axis=1)\n",
    "        \n",
    "        objects['shortest_path'] = shortest_path\n",
    "        objects['rhws'] = gpd.GeoDataFrame(gdf_rhws_single, geometry=\"geometry\", crs=gdf_rhws_single.crs).drop(columns=['representative_point'])\n",
    "        objects['crossings'] = gdf_cross_single.drop(columns=['shortest_path'])\n",
    "        objects['representative_point'] = gpd.GeoDataFrame(gdf_rhws_single, geometry=\"representative_point\", crs=gdf_rhws_single.crs).drop(columns=['geometry'])\n",
    "        objects['nodes'] = gpd.GeoDataFrame(nodes_gdf, geometry=\"geometry\", crs=gdf_cross_single.crs)\n",
    "        \n",
    "        for key, value in objects.items():\n",
    "            # For each GeoDataFrame, save it to a layer in the GeoPackage\n",
    "            value.to_file(f'./shortest_path/Geopackages/{waterschap}_unconnected_{index}.gpkg', layer=key, driver='GPKG')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "# Write final output\n",
    "gdf_out = gpd.GeoDataFrame(pd.concat(gdf_crossings_out))\n",
    "gdf_out['shortest_path'] = gdf_out['shortest_path'].apply(lambda geom: dumps(geom) if geom is not None else None)\n",
    "gdf_out.to_file(f\"/DATAFOLDER/projects/4750_30/Data_shortest_path/{waterschap}/{waterschap}_shortest_path.gpkg\", driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d49d31-c50d-4123-b4c7-00ff1f7b71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e07be-797e-4cfb-a303-2bbb1a7a5a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e66a9-9887-4581-ad73-dc73a97cba73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a0f39-d8b5-4392-ad3d-77ce1cbc4df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ed3bb-e0c7-47e9-a3d5-924e58927073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f2a8f-23d2-4354-a30d-e2376a037867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ribasim]",
   "language": "python",
   "name": "conda-env-ribasim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
